{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 23\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "#常数\n",
    "y = tf.constant(23,name='y')\n",
    "#变量\n",
    "y2 = tf.Variable(23,name='y2')\n",
    "y3 = tf.placeholder(tf.int32) #占位符，类似形参\n",
    "\n",
    "init = tf.global_variables_initializer() #初始化节点\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(y),sess.run(y2))\n",
    "\n",
    "z = tf.identity(y3) #占位符无法引用自身，放入计算图至少需要一个操作\n",
    "value = 23\n",
    "print(sess.run(z,feed_dict={y3:value}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.placeholder(tf.int32)\n",
    "y = tf.placeholder(tf.int32)\n",
    "add = tf.add(x, y)\n",
    "mul = tf.multiply(x, y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(add, feed_dict={x: 2, y: 3}))\n",
    "    print(sess.run(mul, feed_dict={x: 2, y: 3}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.]] [[5. 5.]\n",
      " [5. 5.]]\n"
     ]
    }
   ],
   "source": [
    "matrix1 = tf.constant([[3., 3.]])\n",
    "matrix2 = tf.constant([[2.],[2.]])\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "add = tf.add(matrix1, matrix2)\n",
    "with tf.Session() as sess:\n",
    "    result1 = sess.run(product)\n",
    "    result2 = sess.run(add)\n",
    "    print(result1,result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.15657382]\n",
      " [ 2.95891446]\n",
      " [-1.08926781]\n",
      " [-0.84538042]]\n"
     ]
    }
   ],
   "source": [
    "def linear_function():\n",
    "    np.random.seed(1)\n",
    "    X = tf.constant(np.random.randn(3,1),name='X')\n",
    "    W = tf.constant(np.random.randn(4,3),name='W')\n",
    "    b = tf.constant(np.random.randn(4,1),name='b')\n",
    "    Y = tf.add(tf.matmul(W,X),b)\n",
    "    a = tf.constant(2)\n",
    "    sess = tf.Session()\n",
    "    result = sess.run(Y)\n",
    "    sess.close()\n",
    "    return result\n",
    "print(str(linear_function()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.880797\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    x = tf.placeholder(tf.float32,name = \"x\")\n",
    "    sigmoid = tf.sigmoid(x)\n",
    "    with tf.Session() as sess:\n",
    "        result = sess.run(sigmoid,feed_dict = {x:z})\n",
    "    return result\n",
    "print(sigmoid(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1+np.exp(-x))\n",
    "\n",
    "y2 = np.array([[1,0,0],[0,1,0],[0,0,1],[1,1,0],[0,1,0]])\n",
    "logit2 = np.array([[12,3,2],[3,10,1],[1,2,5],[4,6.5,1.2],[3,6,1]])\n",
    "\n",
    "y2 = np.array(y2).astype(np.float64)\n",
    "sess=tf.Session()\n",
    "cost = tf.nn.sigmoid_cross_entropy_with_logits(labels=y2, logits=logit2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def one_hot_matrix(labels,C):\n",
    "    depth = tf.constant(value=C,name='C')\n",
    "    one_hot_matrix = tf.one_hot(labels,depth,axis=0)\n",
    "    sess = tf.Session()\n",
    "\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    sess.close()\n",
    "    return one_hot\n",
    "\n",
    "labels = np.array([1,2,3,0,2,1])\n",
    "one_hot = one_hot_matrix(labels, C = 4)\n",
    "#4x6矩阵，四行分别对应0，1，2，3；元素为1表示出现的位置\n",
    "print (str(one_hot)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ones =[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "def ones(shape):\n",
    "    ones = tf.ones(3)\n",
    "    sess = tf.Session()\n",
    "    ones = sess.run(ones)\n",
    "\n",
    "    sess.close()\n",
    "    return ones\n",
    "print('ones ='+str(ones([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "0.9673314 [-0.03126341]\n",
      "0.48626995 [0.08869851]\n",
      "0.2848784 [0.19886586]\n",
      "0.18848737 [0.25159472]\n",
      "0.14235221 [0.27683204]\n",
      "0.1202708 [0.28891128]\n",
      "0.109702095 [0.29469267]\n",
      "0.10464371 [0.29745975]\n",
      "0.1022226 [0.2987842]\n",
      "0.10106378 [0.2994181]\n",
      "0.100509144 [0.2997215]\n",
      "0.10024368 [0.2998667]\n",
      "0.10011664 [0.2999362]\n",
      "0.10005582 [0.29996946]\n",
      "0.10002676 [0.29998535]\n",
      "0.10001288 [0.29999298]\n",
      "0.100006215 [0.29999664]\n",
      "0.100003086 [0.29999834]\n",
      "0.10000146 [0.2999992]\n",
      "0.1000008 [0.29999954]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = x_data*0.1+0.3\n",
    "print (x_data.shape)\n",
    "xs = tf.placeholder(tf.float32)\n",
    "ys = tf.placeholder(tf.float32)\n",
    "W = tf.Variable(1.0)\n",
    "#W = tf.Variable(tf.random_uniform([1],-1.0,1))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "y_pre = W*xs+b\n",
    "\n",
    "loss = tf.reduce_mean((tf.square(ys-y_pre)))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(1000):\n",
    "    sess.run(train_step,feed_dict={xs:x_data,ys:y_data})\n",
    "    if i%50 == 0:\n",
    "        print (sess.run(W),sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15489498] [0.2511416]\n",
      "[0.12930092] [0.17310469]\n",
      "[0.15193878] [0.18599911]\n",
      "[0.16019374] [0.17459404]\n",
      "[0.17131877] [0.17043515]\n",
      "[0.18066332] [0.1648303]\n",
      "[0.18957615] [0.16012247]\n",
      "[0.19775574] [0.15563212]\n",
      "[0.20534799] [0.1515112]\n",
      "[0.21237136] [0.1476862]\n",
      "[0.21887499] [0.14414778]\n",
      "[0.22489555] [0.14087121]\n",
      "[0.2304694] [0.13783802]\n",
      "[0.23562957] [0.13502988]\n",
      "[0.2404068] [0.13243017]\n",
      "[0.24482948] [0.13002338]\n",
      "[0.24892393] [0.1277952]\n",
      "[0.2527145] [0.1257324]\n",
      "[0.25622377] [0.12382268]\n",
      "[0.2594726] [0.1220547]\n",
      "[0.26248032] [0.12041792]\n",
      "[0.2652648] [0.11890262]\n",
      "[0.26784265] [0.11749978]\n",
      "[0.2702292] [0.11620105]\n",
      "[0.27243862] [0.1149987]\n",
      "[0.27448407] [0.11388557]\n",
      "[0.2763777] [0.11285507]\n",
      "[0.27813083] [0.11190104]\n",
      "[0.27975383] [0.11101781]\n",
      "[0.28125638] [0.11020013]\n",
      "[0.28264743] [0.10944314]\n",
      "[0.28393525] [0.10874232]\n",
      "[0.2851275] [0.10809351]\n",
      "[0.28623125] [0.10749286]\n",
      "[0.28725308] [0.10693677]\n",
      "[0.2881991] [0.10642197]\n",
      "[0.2890749] [0.10594536]\n",
      "[0.2898857] [0.10550413]\n",
      "[0.29063633] [0.10509564]\n",
      "[0.29133126] [0.10471747]\n",
      "[0.2919746] [0.10436736]\n",
      "[0.2925702] [0.10404324]\n",
      "[0.2931216] [0.10374317]\n",
      "[0.2936321] [0.10346537]\n",
      "[0.29410467] [0.10320818]\n",
      "[0.2945422] [0.1029701]\n",
      "[0.29494724] [0.10274968]\n",
      "[0.29532224] [0.10254561]\n",
      "[0.29566938] [0.10235668]\n",
      "[0.29599077] [0.10218179]\n",
      "[0.2962883] [0.10201988]\n",
      "[0.29656377] [0.10186997]\n",
      "[0.2968188] [0.10173119]\n",
      "[0.2970549] [0.10160271]\n",
      "[0.29727346] [0.10148376]\n",
      "[0.2974758] [0.10137365]\n",
      "[0.29766315] [0.1012717]\n",
      "[0.29783657] [0.10117732]\n",
      "[0.29799712] [0.10108995]\n",
      "[0.29814577] [0.10100906]\n",
      "[0.29828337] [0.10093417]\n",
      "[0.29841077] [0.10086485]\n",
      "[0.2985287] [0.10080066]\n",
      "[0.2986379] [0.10074125]\n",
      "[0.298739] [0.10068624]\n",
      "[0.29883257] [0.10063531]\n",
      "[0.2989192] [0.10058816]\n",
      "[0.2989994] [0.10054451]\n",
      "[0.29907367] [0.10050411]\n",
      "[0.29914242] [0.10046669]\n",
      "[0.29920605] [0.10043205]\n",
      "[0.29926497] [0.1004]\n",
      "[0.2993195] [0.10037031]\n",
      "[0.29937002] [0.10034283]\n",
      "[0.29941678] [0.10031739]\n",
      "[0.29946005] [0.10029383]\n",
      "[0.29950014] [0.10027203]\n",
      "[0.29953724] [0.10025183]\n",
      "[0.29957157] [0.10023315]\n",
      "[0.29960337] [0.10021584]\n",
      "[0.29963282] [0.10019982]\n",
      "[0.29966006] [0.10018498]\n",
      "[0.2996853] [0.10017127]\n",
      "[0.29970863] [0.10015855]\n",
      "[0.29973027] [0.10014679]\n",
      "[0.29975027] [0.10013589]\n",
      "[0.2997688] [0.10012582]\n",
      "[0.29978597] [0.10011648]\n",
      "[0.29980186] [0.10010783]\n",
      "[0.29981658] [0.10009982]\n",
      "[0.2998302] [0.10009241]\n",
      "[0.2998428] [0.10008555]\n",
      "[0.29985446] [0.10007919]\n",
      "[0.29986528] [0.10007332]\n",
      "[0.29987526] [0.10006788]\n",
      "[0.29988453] [0.10006285]\n",
      "[0.29989308] [0.10005818]\n",
      "[0.299901] [0.10005387]\n",
      "[0.29990837] [0.10004988]\n",
      "[0.29991516] [0.10004617]\n",
      "[0.29992145] [0.10004275]\n",
      "[0.2999273] [0.10003957]\n",
      "[0.2999327] [0.10003663]\n",
      "[0.2999377] [0.10003392]\n",
      "[0.2999423] [0.10003139]\n",
      "[0.2999466] [0.10002906]\n",
      "[0.29995057] [0.10002691]\n",
      "[0.29995424] [0.1000249]\n",
      "[0.29995763] [0.10002305]\n",
      "[0.2999608] [0.10002135]\n",
      "[0.29996368] [0.10001975]\n",
      "[0.2999664] [0.1000183]\n",
      "[0.2999689] [0.10001693]\n",
      "[0.2999712] [0.10001567]\n",
      "[0.29997334] [0.10001452]\n",
      "[0.2999753] [0.10001343]\n",
      "[0.29997715] [0.10001244]\n",
      "[0.29997885] [0.10001151]\n",
      "[0.29998043] [0.10001066]\n",
      "[0.2999819] [0.10000986]\n",
      "[0.29998323] [0.10000912]\n",
      "[0.29998448] [0.10000845]\n",
      "[0.29998562] [0.10000782]\n",
      "[0.2999867] [0.10000724]\n",
      "[0.29998767] [0.10000671]\n",
      "[0.2999886] [0.10000622]\n",
      "[0.29998943] [0.10000575]\n",
      "[0.2999902] [0.10000532]\n",
      "[0.29999092] [0.10000493]\n",
      "[0.2999916] [0.10000458]\n",
      "[0.29999223] [0.10000423]\n",
      "[0.2999928] [0.10000391]\n",
      "[0.29999334] [0.10000363]\n",
      "[0.29999384] [0.10000335]\n",
      "[0.2999943] [0.1000031]\n",
      "[0.2999947] [0.10000288]\n",
      "[0.2999951] [0.10000267]\n",
      "[0.29999545] [0.10000247]\n",
      "[0.29999578] [0.1000023]\n",
      "[0.2999961] [0.10000213]\n",
      "[0.29999638] [0.10000196]\n",
      "[0.29999664] [0.10000183]\n",
      "[0.29999688] [0.10000169]\n",
      "[0.29999712] [0.10000157]\n",
      "[0.29999733] [0.10000145]\n",
      "[0.29999754] [0.10000134]\n",
      "[0.29999772] [0.10000125]\n",
      "[0.2999979] [0.10000115]\n",
      "[0.29999804] [0.10000106]\n",
      "[0.2999982] [0.10000098]\n",
      "[0.29999834] [0.10000091]\n",
      "[0.29999846] [0.10000084]\n",
      "[0.29999858] [0.10000078]\n",
      "[0.2999987] [0.10000072]\n",
      "[0.2999988] [0.10000066]\n",
      "[0.29999888] [0.10000061]\n",
      "[0.29999897] [0.10000056]\n",
      "[0.29999906] [0.10000052]\n",
      "[0.29999912] [0.10000047]\n",
      "[0.29999918] [0.10000045]\n",
      "[0.29999924] [0.10000042]\n",
      "[0.2999993] [0.10000039]\n",
      "[0.29999936] [0.10000036]\n",
      "[0.29999942] [0.10000033]\n",
      "[0.29999945] [0.1000003]\n",
      "[0.29999948] [0.10000028]\n",
      "[0.2999995] [0.10000026]\n",
      "[0.29999954] [0.10000025]\n",
      "[0.29999956] [0.10000023]\n",
      "[0.2999996] [0.10000022]\n",
      "[0.29999962] [0.1000002]\n",
      "[0.29999965] [0.10000019]\n",
      "[0.29999968] [0.10000017]\n",
      "[0.2999997] [0.10000016]\n",
      "[0.29999974] [0.10000014]\n",
      "[0.29999977] [0.10000013]\n",
      "[0.29999977] [0.10000011]\n",
      "[0.2999998] [0.10000011]\n",
      "[0.2999998] [0.1000001]\n",
      "[0.29999983] [0.1000001]\n",
      "[0.29999983] [0.10000008]\n",
      "[0.29999986] [0.10000008]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n",
      "[0.29999986] [0.10000007]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.random.rand(100).astype(np.float)\n",
    "y_data = x_data*0.3+0.1\n",
    "\n",
    "W = tf.Variable(tf.zeros([1]))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "y_pre = W*x_data+b\n",
    "loss = tf.reduce_mean(tf.square(y_data-y_pre))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(1000):\n",
    "    sess.run(train_step)\n",
    "    print(sess.run(W),sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fork from https://github.com/aymericdamien/TensorFlow-Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/shengwan/Desktop/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/shengwan/Desktop/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/shengwan/Desktop/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/shengwan/Desktop/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-165-1e908e621082>:65: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "Step 1, Minibatch Loss= 2.9953, Training Accuracy= 0.102\n",
      "Step 200, Minibatch Loss= 2.1417, Training Accuracy= 0.273\n",
      "Step 400, Minibatch Loss= 1.9960, Training Accuracy= 0.352\n",
      "Step 600, Minibatch Loss= 1.8255, Training Accuracy= 0.383\n",
      "Step 800, Minibatch Loss= 1.6349, Training Accuracy= 0.500\n",
      "Step 1000, Minibatch Loss= 1.4520, Training Accuracy= 0.555\n",
      "Step 1200, Minibatch Loss= 1.4540, Training Accuracy= 0.531\n",
      "Step 1400, Minibatch Loss= 1.3627, Training Accuracy= 0.562\n",
      "Step 1600, Minibatch Loss= 1.3778, Training Accuracy= 0.594\n",
      "Step 1800, Minibatch Loss= 1.5085, Training Accuracy= 0.453\n",
      "Step 2000, Minibatch Loss= 1.2105, Training Accuracy= 0.633\n",
      "Step 2200, Minibatch Loss= 1.1672, Training Accuracy= 0.633\n",
      "Step 2400, Minibatch Loss= 1.1828, Training Accuracy= 0.641\n",
      "Step 2600, Minibatch Loss= 0.9635, Training Accuracy= 0.672\n",
      "Step 2800, Minibatch Loss= 0.9889, Training Accuracy= 0.719\n",
      "Step 3000, Minibatch Loss= 1.1075, Training Accuracy= 0.633\n",
      "Step 3200, Minibatch Loss= 0.9529, Training Accuracy= 0.703\n",
      "Step 3400, Minibatch Loss= 0.8446, Training Accuracy= 0.750\n",
      "Step 3600, Minibatch Loss= 0.9294, Training Accuracy= 0.672\n",
      "Step 3800, Minibatch Loss= 0.9770, Training Accuracy= 0.680\n",
      "Step 4000, Minibatch Loss= 0.9384, Training Accuracy= 0.711\n",
      "Step 4200, Minibatch Loss= 0.8174, Training Accuracy= 0.766\n",
      "Step 4400, Minibatch Loss= 0.8288, Training Accuracy= 0.750\n",
      "Step 4600, Minibatch Loss= 0.8847, Training Accuracy= 0.719\n",
      "Step 4800, Minibatch Loss= 1.0930, Training Accuracy= 0.641\n",
      "Step 5000, Minibatch Loss= 0.6900, Training Accuracy= 0.781\n",
      "Step 5200, Minibatch Loss= 0.6873, Training Accuracy= 0.773\n",
      "Step 5400, Minibatch Loss= 0.7107, Training Accuracy= 0.773\n",
      "Step 5600, Minibatch Loss= 0.7790, Training Accuracy= 0.742\n",
      "Step 5800, Minibatch Loss= 0.7304, Training Accuracy= 0.812\n",
      "Step 6000, Minibatch Loss= 0.5698, Training Accuracy= 0.836\n",
      "Step 6200, Minibatch Loss= 0.6461, Training Accuracy= 0.773\n",
      "Step 6400, Minibatch Loss= 0.6236, Training Accuracy= 0.812\n",
      "Step 6600, Minibatch Loss= 0.7344, Training Accuracy= 0.719\n",
      "Step 6800, Minibatch Loss= 0.5820, Training Accuracy= 0.812\n",
      "Step 7000, Minibatch Loss= 0.6384, Training Accuracy= 0.797\n",
      "Step 7200, Minibatch Loss= 0.6881, Training Accuracy= 0.773\n",
      "Step 7400, Minibatch Loss= 0.5985, Training Accuracy= 0.844\n",
      "Step 7600, Minibatch Loss= 0.5878, Training Accuracy= 0.781\n",
      "Step 7800, Minibatch Loss= 0.5387, Training Accuracy= 0.828\n",
      "Step 8000, Minibatch Loss= 0.6040, Training Accuracy= 0.758\n",
      "Step 8200, Minibatch Loss= 0.5824, Training Accuracy= 0.844\n",
      "Step 8400, Minibatch Loss= 0.5326, Training Accuracy= 0.852\n",
      "Step 8600, Minibatch Loss= 0.5069, Training Accuracy= 0.836\n",
      "Step 8800, Minibatch Loss= 0.5639, Training Accuracy= 0.820\n",
      "Step 9000, Minibatch Loss= 0.5698, Training Accuracy= 0.812\n",
      "Step 9200, Minibatch Loss= 0.5772, Training Accuracy= 0.797\n",
      "Step 9400, Minibatch Loss= 0.6681, Training Accuracy= 0.789\n",
      "Step 9600, Minibatch Loss= 0.4503, Training Accuracy= 0.844\n",
      "Step 9800, Minibatch Loss= 0.4504, Training Accuracy= 0.875\n",
      "Step 10000, Minibatch Loss= 0.4513, Training Accuracy= 0.836\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.8671875\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets(\"/Users/shengwan/Desktop/MNIST_data\", one_hot=True)\n",
    "# Need to download mnist data first and import from your file\n",
    "MNIST_data_folder='/Users/shengwan/Desktop/MNIST_data'  \n",
    "mnist=input_data.read_data_sets(MNIST_data_folder,one_hot=True)\n",
    "\n",
    "'''\n",
    "To classify images using a recurrent neural network, we consider every image\n",
    "row as a sequence of pixels. Because MNIST image shape is 28*28px, we will then\n",
    "handle 28 sequences of 28 steps for every sample.\n",
    "'''\n",
    "\n",
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "training_steps = 10000\n",
    "batch_size = 128\n",
    "display_step = 200\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 28 # MNIST data input (img shape: 28*28)\n",
    "timesteps = 28 # timesteps\n",
    "num_hidden = 128 # hidden layer num of features\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, training_steps+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Reshape data to get 28 seq of 28 elements\n",
    "        batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 128 mnist test images\n",
    "    test_len = 128\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_input))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
